{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competición CNN \n",
    "\n",
    "Autores: David García Lleyda, Álvaro Martínez Parpolowicz, Alexis Gómez Chimeno\n",
    "\n",
    "Clase: MAIS 5ºA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import scipy\n",
    "from tensorflow.keras.layers import CategoryEncoding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import metrics,layers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib \n",
    "import optuna\n",
    "import plotly\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from pprint import pprint\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Declaración de MLflow\n",
    "\n",
    "Vamos a utilizar Mlflow que es una herramienta del ámbito de MLOps para hacer un seguimiento de las diferentes características de la CNN. De esta manera conseguimos guardar los resultados y compararlos de forma sencilla.\n",
    "\n",
    "En las siguientes celdas declaramos el experimento y especificamos la URI con la que se debe comunicar para mostrar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "experiment_description = (\n",
    "    \"This is the multilabel classification project for VICO. \"\n",
    "    \"This experiment contains the produce models for multilabel classification.\"\n",
    ")\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"multilabel_classification\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q1-2024\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "produce_multilabel_experiment = client.create_experiment(\n",
    "    name=\"Multilabel_Model\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solución del ejercicio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Comprobación de dispositivos disponibles donde entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, como el objetivo es utilizar aceleración por GPU para agilizar los cálculos de la CNN, vamos a comprobar que tensorflow detecta la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que sí la detecta. En caso de no detectarla, el código seguiría funcionando pero el entrenamiento sería mucho más lento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Carga de los datos y etiquetas previamente guardadas\n",
    "\n",
    "En esta sección definiremos las rutas de donde se van a coger las imágenes, calcularemos el tamaño de la imagen más pequeña, cargaremos las etiquetas correspondientes a cada una de las imágenes desde un formato .json y guardaremos los nombre de los archivos así como las etiquetas en un dataframe.\n",
    "\n",
    "Este último paso es necesario por varios motivos:\n",
    "\n",
    "1. Los generadores de tensorflow son necesarios para poder ir cargando por lotes las imágenes a la GPU y no sobrecargar su VRAM.\n",
    "2. Los generadores permiten definir ciertas características como son el tamaño de los batches, si los datos deben mezclarse de forma aleatoria, la semilla a utilizar y un tamaño objetivo para cargar las imágenes.\n",
    "\n",
    "Ambos motivos hacen que sean imprescindible para el correcto funcionamiento y entrenamiento del modelo.\n",
    "\n",
    "Además, también definimos en una lista las 5 posibles etiquetas que asignamos en el entrenamiento multietiqueta a cada una de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path_train='./Sports_Final/train/'\n",
    "relative_path_valid='./Sports/valid/'\n",
    "relative_path_test='./Sports/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smallest_image_in_folder(path):\n",
    "    images = os.listdir(path)\n",
    "    smallest_image = None\n",
    "    smallest_diagonal = float('inf')\n",
    "    for image in images:\n",
    "        image_path = os.path.join(path, image)\n",
    "        current_image = cv2.imread(image_path)\n",
    "        diagonal_length = np.sqrt(current_image.shape[0]**2 + current_image.shape[1]**2)\n",
    "        if diagonal_length < smallest_diagonal:\n",
    "            smallest_diagonal = diagonal_length\n",
    "            smallest_image = current_image\n",
    "    return smallest_image.shape[0], smallest_image.shape[1]\n",
    "\n",
    "for path in [relative_path_train, relative_path_valid, relative_path_test]:\n",
    "    dirs_in_path=os.listdir(path)\n",
    "    smallest_diagonal = float('inf')\n",
    "    smallest_image=None\n",
    "    for dir in dirs_in_path:\n",
    "        dir_path=os.path.join(path,dir)\n",
    "        smallest_image_width,smallest_image_height=calculate_smallest_image_in_folder(dir_path)\n",
    "        actual_image=np.zeros((smallest_image_width,smallest_image_height,3))\n",
    "        actual_diagonal = np.sqrt(smallest_image_width**2 + smallest_image_height**2)\n",
    "        if actual_diagonal<smallest_diagonal:\n",
    "            smallest_diagonal=actual_diagonal\n",
    "            smallest_image=actual_image\n",
    "            print(f'Smallest image in {dir_path} has width {smallest_image_width} and height {smallest_image_height}')\n",
    "\n",
    "print('Smallest image has dimensions', smallest_image.shape) ## Too big for our purposes\n",
    "print('Smallest image has diagonal', smallest_diagonal) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width=smallest_image.shape[0]\n",
    "# height=smallest_image.shape[1]\n",
    "width=64\n",
    "height=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['animals', 'car', 'cycle', 'person', 'water']\n",
    "filename_column='filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('one_hot_train_augmented_by_folders.json','r') as file:\n",
    "    train_data = json.load(file)\n",
    "    file.close()\n",
    "# Create an empty list to store the data\n",
    "data_train_list = []\n",
    "\n",
    "# Iterate over the items in the JSON file\n",
    "for filename, one_hot_vector in train_data.items():\n",
    "    # Append the filename and one-hot vector as a tuple to the list\n",
    "    data_train_list.append((filename, one_hot_vector))\n",
    "\n",
    "# Convert the list of tuples into a pandas DataFrame\n",
    "df_train = pd.DataFrame(data_train_list)\n",
    "\n",
    "df_train.columns = [filename_column, 'One-Hot Vector']\n",
    "# Split the \"One-Hot Vector\" column into separate columns\n",
    "df_train[columns] = pd.DataFrame(df_train['One-Hot Vector'].tolist())\n",
    "\n",
    "# Rename the columns to match the categories\n",
    "df_train.drop(columns=['One-Hot Vector'], inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('one_hot_valid_by_folders.json','r') as file:\n",
    "    valid_data = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data_valid_list = []\n",
    "\n",
    "# Iterate over the items in the JSON file\n",
    "for filename, one_hot_vector in valid_data.items():\n",
    "    # Append the filename and one-hot vector as a tuple to the list\n",
    "    data_valid_list.append((filename, one_hot_vector))\n",
    "\n",
    "# Convert the list of tuples into a pandas DataFrame\n",
    "df_valid = pd.DataFrame(data_valid_list)\n",
    "\n",
    "df_valid.columns = [filename_column, 'One-Hot Vector']\n",
    "# Split the \"One-Hot Vector\" column into separate columns\n",
    "df_valid[columns] = pd.DataFrame(df_valid['One-Hot Vector'].tolist())\n",
    "\n",
    "# Rename the columns to match the categories\n",
    "df_valid.drop(columns=['One-Hot Vector'], inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('one_hot_test_by_folders.json','r') as file:\n",
    "    test_data = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data_test_list = []\n",
    "\n",
    "# Iterate over the items in the JSON file\n",
    "for filename, one_hot_vector in test_data.items():\n",
    "    # Append the filename and one-hot vector as a tuple to the list\n",
    "    data_test_list.append((filename, one_hot_vector))\n",
    "\n",
    "# Convert the list of tuples into a pandas DataFrame\n",
    "df_test = pd.DataFrame(data_test_list)\n",
    "\n",
    "df_test.columns = [filename_column, 'One-Hot Vector']\n",
    "# Split the \"One-Hot Vector\" column into separate columns\n",
    "df_test[columns] = pd.DataFrame(df_test['One-Hot Vector'].tolist())\n",
    "\n",
    "# Rename the columns to match the categories\n",
    "df_test.drop(columns=['One-Hot Vector'], inplace=True)\n",
    "# Replace \"False\" with 0 and \"True\" with 1 in the DataFrame\n",
    "df_test.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_train,\n",
    "directory=relative_path_train,\n",
    "x_col=filename_column,\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df_valid,\n",
    "directory=relative_path_valid,\n",
    "x_col=filename_column,\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df_test,\n",
    "directory=relative_path_test,\n",
    "x_col=filename_column,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = [(load_image(relative_path_train + i), train_data[i]) for i in train_data]\n",
    "# valid= [(load_image(relative_path_valid + i), valid_data[i]) for i in valid_data]\n",
    "# test = [(load_image(relative_path_test + i), test_data[i]) for i in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = np.array([t[0] for t in train], dtype='float32')\n",
    "# train_labels = np.array([t[1] for t in train], dtype='float32')\n",
    "# valid_images = np.array([t[0] for t in valid],  dtype='float32')\n",
    "# valid_labels = np.array([t[1] for t in valid], dtype='float32')\n",
    "# test_images = np.array([t[0] for t in test],  dtype='float32')\n",
    "# test_labels = np.array([t[1] for t in test], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Definición de la arquitectura del modelo y sus hiperparámetros\n",
    "\n",
    "En esta sección definimos cada uno de los hiperpárametros de la red, sus callbacks y su arquitectura.\n",
    "\n",
    "Esta sección acaba con el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_SIZE_TRAIN=train_generator.n\n",
    "PREDICT_SIZE_TEST=test_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model_callback = ModelCheckpoint(\n",
    "    filepath=\"best_model.h5\",\n",
    "    monitor=\"val_f1_score\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"max\",\n",
    "    verbose=1,\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_f1_score\",  # Choose the metric to monitor for improvement\n",
    "    patience=8,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    ")\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor=\"val_f1_score\", factor=0.2, patience=3, mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_filters=32\n",
    "second_layer_filters=64\n",
    "third_layer_filters=128\n",
    "fourth_layer_filters=256\n",
    "# fifth_layer_neurons=512\n",
    "kernel_size_first_layer=(3,3)\n",
    "kernel_size_second_layer=(5,5)\n",
    "kernel_size_third_layer=(3,3)\n",
    "kernel_size_fourth_layer=(5,5)\n",
    "max_pooling_size=(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    # model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"))\n",
    "    # model.add(layers.experimental.preprocessing.RandomRotation(0.2))\n",
    "    model.add(Conv2D(first_layer_filters, kernel_size_first_layer,padding='same', activation='relu', input_shape=(width,height,3)))\n",
    "    model.add(Conv2D(first_layer_filters, kernel_size_first_layer,padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(max_pooling_size))\n",
    "\n",
    "    model.add(Conv2D(second_layer_filters, kernel_size_second_layer, activation='relu',padding='same'))\n",
    "    model.add(Conv2D(second_layer_filters, kernel_size_second_layer,padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(max_pooling_size))\n",
    "\n",
    "    model.add(Conv2D(third_layer_filters, kernel_size_third_layer, activation='relu',padding='same'))\n",
    "    model.add(Conv2D(third_layer_filters, kernel_size_third_layer, activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(max_pooling_size))\n",
    "\n",
    "    model.add(Conv2D(fourth_layer_filters, kernel_size_second_layer, activation='relu',padding='same'))\n",
    "    model.add(Conv2D(fourth_layer_filters, kernel_size_second_layer, activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(max_pooling_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(width*width,kernel_initializer=\"random_normal\", activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(256,kernel_initializer=\"random_normal\", activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "    model.add(Dense(5, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=[tfa.metrics.F1Score(average=\"macro\",num_classes=5,threshold=0.5)])\n",
    "\n",
    "    history = model.fit(x=train_generator,steps_per_epoch=STEP_SIZE_TRAIN,validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,\n",
    "                        epochs=40,callbacks=[save_best_model_callback,early_stopping_callback,reduce_lr_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualización de la evolución de las métricas\n",
    "\n",
    "En esta sección se implementan las gráficas de evolución de las métricas de interés de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('model f1_score')\n",
    "plt.ylabel('f1_score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Guardado del modelo\n",
    "\n",
    "Esta sección trata la implementación del guardado del modelo generado por el entrenamiento en un archivo .h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_convolucionesApiladas_2densas.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Generación de las predicciones\n",
    "\n",
    "\n",
    "Con el modelo ya entrenado, falta generar las predicciones que realiza el modelo sobre los datos de train y test. Para ello se realizan varios pasos:\n",
    "\n",
    "1. Se utiliza un nuevo generador que utilice lotes de una imagen para que los resultados de las métricas no vengan condicionados por el tamaño de lote. El objetivo principal es quedarse con la métrica evaluada habiendo hecho la predicción de las imágenes una por una.\n",
    "2. Se utiliza la función model.predict pasándole todos los datos de train por un lado y todos los datos de test por otro. Esto genera la probabilidad de pertenencia a cada una de las clases definidas en la etiqueta por cada imagen.\n",
    "3. Se define un umbral de clasificación a partir del cual consideraremos que pertenece a una clase u otra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_to_predict=datagen.flow_from_dataframe(\n",
    "dataframe=df_train,\n",
    "directory=relative_path_train,\n",
    "x_col=filename_column,\n",
    "y_col=columns,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred_test=model.predict(x=test_generator,\n",
    "steps=PREDICT_SIZE_TEST,\n",
    "verbose=1)\n",
    "train_generator_to_predict.reset()\n",
    "pred_train=model.predict(x=train_generator_to_predict,\n",
    "steps=PREDICT_SIZE_TRAIN,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se ha decidido utilizar un umbral de 0.5. No es mayor que 0.5 puesto que no necesitamos que el modelo esté completamente seguro de su pertenencia a una clase para clasificarlo como tal. De igual modo, no se establece un umbral menor para no sesgar a la hora de evalúar la pertenencia o no, indicando el mismo tamaño para la pertenencia de una clase como su no pertenencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool_test=(pred_test >0.5).astype(int)\n",
    "pred_bool_train=(pred_train >0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df_train.copy()\n",
    "df_test2 = df_test.copy()\n",
    "\n",
    "columns_to_encode = [col for col in df_train2.columns if col != filename_column]\n",
    "\n",
    "# Encode the columns into one-hot vectors\n",
    "df_train2[columns_to_encode] = df_train2[columns_to_encode].apply(lambda x: x.astype(int))\n",
    "df_test2[columns_to_encode] = df_test2[columns_to_encode].apply(lambda x: x.astype(int))\n",
    "\n",
    "# Convert the rows into a numpy array\n",
    "train_labels = df_train2[columns_to_encode].to_numpy()\n",
    "test_labels = df_test2[columns_to_encode].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Generación y visualiación de la matriz de confusión\n",
    "En esta sección se implementa el código para generar las matrices de confusión y su visualización. Estas matrices se generaran tanto para los datos de test como para los de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrices,type='train'):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.set(font_scale=1.2)  # Adjust font size if needed\n",
    "    for i, conf_matrix in enumerate(conf_matrices, 1):\n",
    "        plt.subplot(3, 2, i)\n",
    "        conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2%\", cmap=\"Blues\", cbar=False,\n",
    "                    xticklabels=[\"Class 0\", \"Class 1\"],\n",
    "                    yticklabels=[\"Class 0\", \"Class 1\"])\n",
    "        plt.title(f\"Confusion Matrix {columns[i-1]} \"+type)\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(multilabel_confusion_matrix(train_labels, pred_bool_train),type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(multilabel_confusion_matrix(test_labels, pred_bool_test),type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que hay underfitting por parte del modelo, ya que parece que está confundiendo de más las imágenes modificadas pero que las imágenes originales las acierta de manera considerable. Esto lo vemos por la diferencia de resultados en train y en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Evaluación de las métricas del modelo\n",
    "A continuación, se calculan las métricas asociadas al modelo. Concretamente, se muestran por pantalla los resultados de las métricas en dos niveles:\n",
    "1. A nivel de cada clase en las etiquetas.\n",
    "2. Utilizando el valor de 'macro' para hacer una media aritmética de todas las clases dentro de la etiqueta.\n",
    "3. Utilizando el valor 'weighted' que hace una media ponderada de cada una de las clases dentro de la etiqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1 Métricas de cada clase en la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = accuracy_score(train_labels, pred_bool_train)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_train = f1_score(train_labels, pred_bool_train, average=None)\n",
    "\n",
    "# Calculate precision\n",
    "precision_train = precision_score(train_labels, pred_bool_train, average=None)\n",
    "\n",
    "# Calculate recall\n",
    "recall_train = recall_score(train_labels, pred_bool_train, average=None)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_test = accuracy_score(test_labels, pred_bool_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_test = f1_score(test_labels, pred_bool_test, average=None)\n",
    "\n",
    "# Calculate precision\n",
    "precision_test= precision_score(test_labels, pred_bool_test, average=None)\n",
    "\n",
    "# Calculate recall\n",
    "recall_test = recall_score(test_labels, pred_bool_test, average=None)\n",
    "\n",
    "print(\"Accuracy train:\", accuracy_train)\n",
    "print(\"F1 Score train:\", f1_train)\n",
    "print(\"Precision train:\", precision_train)\n",
    "print(\"Recall train:\", recall_train)\n",
    "print(\"Accuracy test:\", accuracy_test)\n",
    "print(\"F1 Score test:\", f1_test)\n",
    "print(\"Precision test:\", precision_test)\n",
    "print(\"Recall test:\", recall_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.2 Métricas calculadas de forma MACRO (media aritmética)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_train = accuracy_score(train_labels, pred_bool_train)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_train = f1_score(train_labels, pred_bool_train, average='macro')\n",
    "\n",
    "# Calculate precision\n",
    "precision_train = precision_score(train_labels, pred_bool_train, average='macro')\n",
    "\n",
    "# Calculate recall\n",
    "recall_train = recall_score(train_labels, pred_bool_train, average='macro')\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_test = accuracy_score(test_labels, pred_bool_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_test = f1_score(test_labels, pred_bool_test, average='macro')\n",
    "\n",
    "# Calculate precision\n",
    "precision_test= precision_score(test_labels, pred_bool_test, average='macro')\n",
    "\n",
    "# Calculate recall\n",
    "recall_test = recall_score(test_labels, pred_bool_test, average='macro')\n",
    "\n",
    "print(\"Accuracy train:\", accuracy_train)\n",
    "print(\"F1 Score train:\", f1_train)\n",
    "print(\"Precision train:\", precision_train)\n",
    "print(\"Recall train:\", recall_train)\n",
    "print(\"Accuracy test:\", accuracy_test)\n",
    "print(\"F1 Score test:\", f1_test)\n",
    "print(\"Precision test:\", precision_test)\n",
    "print(\"Recall test:\", recall_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.3 Métricas calculadas de forma Weighted (media ponderada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_train = accuracy_score(train_labels, pred_bool_train)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_train = f1_score(train_labels, pred_bool_train, average='weighted')\n",
    "\n",
    "# Calculate precision\n",
    "precision_train = precision_score(train_labels, pred_bool_train, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_train = recall_score(train_labels, pred_bool_train, average='weighted')\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_test = accuracy_score(test_labels, pred_bool_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_test = f1_score(test_labels, pred_bool_test, average='weighted')\n",
    "\n",
    "# Calculate precision\n",
    "precision_test= precision_score(test_labels, pred_bool_test, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_test = recall_score(test_labels, pred_bool_test, average='weighted')\n",
    "\n",
    "print(\"Accuracy train:\", accuracy_train)\n",
    "print(\"F1 Score train:\", f1_train)\n",
    "print(\"Precision train:\", precision_train)\n",
    "print(\"Recall train:\", recall_train)\n",
    "print(\"Accuracy test:\", accuracy_test)\n",
    "print(\"F1 Score test:\", f1_test)\n",
    "print(\"Precision test:\", precision_test)\n",
    "print(\"Recall test:\", recall_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es de esperar que la media ponderada según el número de apariciones de cada una de las clases sea mayor, puesto que mayoritariamente aparecen personas en todas las imágenes. Por este motivo, consideramos que la media aritmética es más representativa de la capacidad de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Guardado de resultado en el backend de Mlflow\n",
    "\n",
    "En este apartado se indica el código a través del cual cargamos el modelo y especificamos todos los hiperparámetros utilizados por la red neuronal para guardarlo en el backend de Mlflow.\n",
    "\n",
    "Es importante resaltar que como el modelo ha sido entrenado en GPU, al cargarlo con el parámetro \"compile\" con valor True, mlflow trata de buscar en las secciones de memoria RAM equivocadas y no carga de forma correcta. Como nuestro objetivo no es guardar el modelo en mlflow, se ha decidido dejar con el compile a False para tener solo una referencia al modelo pero no su archivo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=keras.models.load_model('./model_convolucionesApiladas_2densas.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_experiment = mlflow.set_experiment(\"Multilabel_Model\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"multilabel_model_2dense_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"ar_2dense_rf_test\"\n",
    "\n",
    "params = {\n",
    "    \"kernel_size_first_layer\": kernel_size_first_layer,\n",
    "    \"neurons_first_layer\": first_layer_filters,\n",
    "    \"kernel_size_second_layer\": kernel_size_second_layer,\n",
    "    \"neurons_second_layer\": second_layer_filters,\n",
    "    \"kernel_size_third_layer\": kernel_size_third_layer,\n",
    "    \"neurons_third_layer\": third_layer_filters,\n",
    "    \"kernel_size_fourth_layer\": kernel_size_fourth_layer,\n",
    "    \"neurons_fourth_layer\": fourth_layer_filters,\n",
    "    \"first_big_dense_layer\": 3,\n",
    "    \"second_big_dense_layer\": 2,\n",
    "    \"third_big_dense_layer\": 3,\n",
    "    \"fourth_big_dense_layer\": 3,\n",
    "    \"neurons_dense_layer\": width*width,\n",
    "    \"neurons_dense_layer2\": 256,\n",
    "    \"neurons_dense_layer3\": 5,\n",
    "    \"activation\": \"relu\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"image_size\": (width,height),\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 40,\n",
    "    \"callbacks\": [save_best_model_callback,early_stopping_callback,reduce_lr_callback],\n",
    "    \"initializer\": \"random_normal\",\n",
    "    \"regularizer\": \"l2(0.01)\"\n",
    "}\n",
    "metrics = {\"f1_test\": f1_test, \"precision_test\": precision_test, \"recall_test\": recall_test}\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.keras.log_model(\n",
    "        model2,  \"models\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optuna - Extra\n",
    "\n",
    "Una de las tantas modificaciones que se añadieron a la red original fue el uso del optimizador de hiperparámetros optuna. No obstante, realizar pruebas con distintos hiperpárametros sigue siendo lento por la complejidad de la red establecida. Aunque sus resultados no han sido definitivos para entregar el modelo final, sí que se considera que aportan valor a un futuro refinamiento de la red. Es por este motivo por lo que se aporta el código como una modificación añadida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_train,\n",
    "directory=relative_path_train,\n",
    "x_col=filename_column,\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=None\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial, min_neurons=1, max_neurons=6, max_layers=6):\n",
    "    \"\"\"Función para crear un modelo de red neuronal\"\"\"\n",
    "    \n",
    "    # Número de capas\n",
    "    n_layers = 2\n",
    "    \n",
    "    \n",
    "    # Valor del parámetro de regularización L2\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-3, 1e-1)\n",
    "    \n",
    "    # Red Neuronal\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Valor del kernel size\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 3, 9, step=2)\n",
    "    # Capa oculta 1\n",
    "    num_first_layer = trial.suggest_int(\"n_units_0\", min_neurons, max_neurons)\n",
    "    model.add(Conv2D(num_first_layer, (kernel_size, kernel_size),padding='same', activation='relu', input_shape=(width,height,3)))\n",
    "    model.add(Conv2D(num_first_layer, (kernel_size, kernel_size),padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Resto de capas ocultas\n",
    "    for i in range(n_layers):\n",
    "        num_hidden_neurons = trial.suggest_int(\"n_units_{}\".format(i+1), min_neurons, max_neurons)\n",
    "        model.add(Conv2D(num_hidden_neurons, (kernel_size, kernel_size), activation='relu',padding='same'))\n",
    "        model.add(Conv2D(num_hidden_neurons, (kernel_size, kernel_size),padding='same', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Capa de salida\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(width, activation='relu', kernel_regularizer=l2(weight_decay)))\n",
    "\n",
    "    model.add(Dense(5, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial):\n",
    "    \"\"\"Función que devuelve un optimizador RMSprop o Adam con sus hiperparámetros\"\"\"\n",
    "\n",
    "    kwargs = {}\n",
    "    \n",
    "    # Optimizadores\n",
    "    optimizer_selected = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"Adam\"])\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/RMSprop\n",
    "    if optimizer_selected == \"RMSprop\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"rmsprop_learning_rate\", 1e-3, 1e-1)\n",
    "        kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-3, 1e-1)\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "    elif optimizer_selected == \"Adam\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-2, 1e-1)\n",
    "\n",
    "    return getattr(tf.optimizers, optimizer_selected)(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    \"\"\"Función que se ejecutará en la función \"objetive\" para guardar el mejor modelo\n",
    "    entrenado hasta el momento.\n",
    "    \"\"\"\n",
    "    global best_model\n",
    "    if study.best_trial == trial:\n",
    "        best_model=model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Función que entrena y evalua \"un intento\" de un modelo de red neuronal\"\"\"\n",
    "    global model\n",
    "    save_best_model_callback = ModelCheckpoint(\n",
    "        filepath=\"best_model_optuna.h5\",\n",
    "        monitor=\"val_f1_score\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_f1_score\",  # Choose the metric to monitor for improvement\n",
    "        patience=8,  # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    reduce_lr_callback = ReduceLROnPlateau(\n",
    "        monitor=\"val_f1_score\", factor=0.2, patience=4, mode=\"max\"\n",
    "    )\n",
    "    # Construimos el modelo\n",
    "    model = create_model(trial, max_layers=3, max_neurons=128, min_neurons=32)\n",
    "\n",
    "    # Obtenemos el optimizador\n",
    "    optimizer = create_optimizer(trial)\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[tfa.metrics.F1Score(average=\"macro\", num_classes=5)],\n",
    "    )\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        # Entrenamos el modelo\n",
    "        history = model.fit(\n",
    "            x=train_generator,\n",
    "            steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=STEP_SIZE_VALID,\n",
    "            epochs=20,\n",
    "            callbacks=[\n",
    "                save_best_model_callback,\n",
    "                early_stopping_callback,\n",
    "                reduce_lr_callback,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Definicion de la métrica\n",
    "    test_generator.reset()\n",
    "    pred_test = model.predict(x=test_generator, steps=PREDICT_SIZE_TEST)\n",
    "    pred_bool_test = (pred_test > 0.5).astype(int)\n",
    "\n",
    "    # Evaluamos la red neuronal y devolvemos el valor de la métrica F1 con los datos de test\n",
    "    #     return f1_score(y_true=y_test, y_pred=np.where(model.predict(X_test) > 0.5, 1,0))\n",
    "    return f1_score(test_labels, pred_bool_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model_callback = ModelCheckpoint(\n",
    "    filepath='best_model_optuna.h5',\n",
    "    monitor='val_f1_score',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_f1_score',  # Choose the metric to monitor for improvement\n",
    "    patience=8,            # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor=\"val_f1_score\", factor=0.2, patience=4, mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"MLP Tensorflow\")\n",
    "func = lambda trial: objective(trial=trial)\n",
    "study.optimize(func, n_trials=15, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.save('best_model_optuna.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
